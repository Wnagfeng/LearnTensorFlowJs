# 为什么要进行归一化

归一化是一种常用的预处理方法，它可以对输入数据进行标准化，使得数据在不同范围内的取值都处于同一量纲，从而使得模型训练更加稳定、收敛速度更快。

归一化的目的是为了解决输入数据不同范围的问题，使得模型能够更好地处理输入数据。归一化的过程包括两个步骤：

1. 特征缩放：将所有特征值缩放到同一范围内，如将所有特征值缩放到[0,1]或[-1,1]。
2. 特征中心化：将所有特征值中心化到均值为0的位置。

归一化的好处：

1. 归一化可以使得不同特征之间的数据量级更加一致，从而使得模型训练更加稳定、收敛速度更快。
2. 归一化可以消除不同特征之间量纲的影响，使得模型更加健壮。
3. 归一化可以提高模型的泛化能力，使得模型更加适应不同的数据分布。

归一化的缺点：

1. 归一化会引入噪声，使得模型的泛化能力变差。
2. 归一化会影响模型的收敛速度，降低模型的训练效率。
3. 归一化会引入额外的计算开销，降低模型的效率。

总结：归一化是一种常用的预处理方法，它可以对输入数据进行标准化，使得数据在不同范围内的取值都处于同一量纲，从而使得模型训练更加稳定、收敛速度更快。但是，归一化也有其缺点，需要根据具体的应用场景进行选择。


# 小栗子
想象一下你正在学习一门课程，而这门课程的考试成绩有两个部分组成：课堂表现和期末考试成绩。课堂表现可能是老师根据你的参与度、作业完成情况等方面评定的一个分数，而期末考试成绩则是你在一次大型考试中得到的分数。

现在，假设课堂表现的分数是以10分为满分，而期末考试的分数是以100分为满分。你的课堂表现得了8分，期末考试得了85分。

如果你要把这两个成绩综合起来，你可能会简单地把它们加起来，得到93分。但是，这样的计算方法存在一个问题：课堂表现的分数范围和期末考试的分数范围差异很大，这样课堂表现在综合评价中的权重就显得很小。

这就好比在计算机中进行数值计算时，如果两个特征的数值范围相差太大，就会影响到模型的学习效果。这就是为什么要进行归一化的原因。在这个例子中，你可以对两个成绩进行归一化，将它们都映射到0到1之间的范围内。比如，将课堂表现的8分归一化为0.8，将期末考试的85分归一化为0.85。这样，两个成绩在综合评价中的权重就能够更加平衡，而不会被其中一个数值范围的大小所主导。







